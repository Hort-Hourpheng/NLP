{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upheaving ultimate continental knocks continental knocks rooms knocks rooms Cathedral rooms Cathedral hearts Cathedral hearts 30 hearts 30 paintings 30 paintings northward paintings northward story northward story parlor story parlor oftentimes parlor oftentimes Book oftentimes Book Vedas Book Vedas referring Vedas referring trophies referring trophies considerably trophies considerably thunder considerably thunder walrus thunder walrus slipping\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    :param text: Takes input sentence\n",
    "    :return: tokenized sentence\n",
    "    \"\"\"\n",
    "    for punct in string.punctuation:\n",
    "        text = text.replace(punct, \" \" + punct + \" \")\n",
    "    t = text.split()\n",
    "    return t\n",
    "\n",
    "\n",
    "class NGramModelWithBackoff:\n",
    "    def n_gram_counts(self, text, n):\n",
    "        n_tokens = len(text)\n",
    "        result = dict()\n",
    "        for i in range(n_tokens - n + 1):\n",
    "            key = tuple(text[i : i + n])\n",
    "            if key in result:\n",
    "                result[key] += 1\n",
    "            else:\n",
    "                result[key] = 1\n",
    "        return result\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.uni_counts = self.n_gram_counts(text, 1)\n",
    "        self.bi_counts = self.n_gram_counts(text, 2)\n",
    "        self.tri_counts = self.n_gram_counts(text, 3)\n",
    "        self.four_counts = self.n_gram_counts(text, 4)\n",
    "        self.total_count = sum(self.uni_counts.values())\n",
    "        self.vocab = len(self.uni_counts)\n",
    "\n",
    "    def _get_probability(self, ngram):\n",
    "        if len(ngram) == 1:\n",
    "            return self.uni_counts.get(ngram, 0) / self.total_count\n",
    "        elif len(ngram) == 2:\n",
    "            return self.bi_counts.get(ngram, 0) / self.uni_counts.get(ngram[0], 1)\n",
    "        elif len(ngram) == 3:\n",
    "            return self.tri_counts.get(ngram, 0) / self.bi_counts.get(ngram[:2], 1)\n",
    "        elif len(ngram) == 4:\n",
    "            return self.four_counts.get(ngram, 0) / self.tri_counts.get(ngram[:3], 1)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def generate_starting_trigram(self):\n",
    "        # Start with the most frequent word based on unigram counts\n",
    "        first_word = random.choices(\n",
    "            list(self.uni_counts.keys()), weights=self.uni_counts.values()\n",
    "        )[0]\n",
    "\n",
    "        # Check if there are bigrams matching the first word\n",
    "        matching_bigrams = [\n",
    "            word[1] for word in self.bi_counts.keys() if word[0] == first_word\n",
    "        ]\n",
    "\n",
    "        # If there are matching bigrams, select the most common second word\n",
    "        if matching_bigrams:\n",
    "            second_word = max(\n",
    "                matching_bigrams, key=lambda x: self.bi_counts.get((first_word, x), 0)\n",
    "            )\n",
    "        else:\n",
    "            # If no matching bigrams, select a random second word from the corpus\n",
    "            second_word = random.choice(list(self.uni_counts.keys()))\n",
    "\n",
    "        # Use the bigram along with the preceding word from trigram counts to form a trigram\n",
    "        matching_trigrams = [\n",
    "            word[2]\n",
    "            for word in self.tri_counts.keys()\n",
    "            if word[:2] == (first_word, second_word)\n",
    "        ]\n",
    "        if matching_trigrams:\n",
    "            third_word = max(\n",
    "                matching_trigrams,\n",
    "                key=lambda x: self.tri_counts.get((first_word, second_word, x), 0),\n",
    "            )\n",
    "        else:\n",
    "            # If no matching trigrams, select a random third word from the corpus\n",
    "            third_word = random.choice(list(self.uni_counts.keys()))\n",
    "\n",
    "        return (first_word, second_word, third_word)\n",
    "\n",
    "    def generate_text(self, length):\n",
    "        text = tuple()\n",
    "        starting_trigram = self.generate_starting_trigram()\n",
    "\n",
    "        for _ in range(length - 2):\n",
    "            next_word = self.generate_next_word(starting_trigram)\n",
    "            text += starting_trigram\n",
    "            text += (next_word,)\n",
    "            starting_trigram = text[-2:]\n",
    "\n",
    "        return \" \".join([\" \".join(token) for token in text])\n",
    "\n",
    "    # def generate_next_word(self, given_trigram):\n",
    "    #     max_count = 0\n",
    "    #     next_word = None\n",
    "\n",
    "    #     # Check if the given trigram exists in the four-grams\n",
    "    #     for four_gram, count in self.four_counts.items():\n",
    "    #         if four_gram[:3] == given_trigram:\n",
    "    #             # Update the most common next word if count is greater\n",
    "    #             if count > max_count:\n",
    "    #                 max_count = count\n",
    "    #                 next_word = four_gram[3]\n",
    "\n",
    "    #     # Check if the given trigram exists in the trigrams\n",
    "    #     for tri_gram, count in self.tri_counts.items():\n",
    "    #         if tri_gram[:2] == given_trigram[1:]:\n",
    "    #             # Update the most common next word if count is greater\n",
    "    #             if count > max_count:\n",
    "    #                 max_count = count\n",
    "    #                 next_word = tri_gram[2]\n",
    "\n",
    "    #     # Check if the given trigram exists in the bigrams\n",
    "    #     for bi_gram, count in self.bi_counts.items():\n",
    "    #         if bi_gram[:1] == given_trigram[2:]:\n",
    "    #             # Update the most common next word if count is greater\n",
    "    #             if count > max_count:\n",
    "    #                 max_count = count\n",
    "    #                 next_word = bi_gram[1]\n",
    "\n",
    "    #     # If none of the above cases matched, return the most common word based on unigram counts\n",
    "    #     if next_word is None:\n",
    "    #         next_word = max(self.uni_counts, key=self.uni_counts.get)\n",
    "\n",
    "    #     return next_word\n",
    "    def generate_next_word(self, given_trigram):\n",
    "        # Collect all possible next words and their probabilities\n",
    "        possible_next_words = []\n",
    "        total_weight = 0\n",
    "        for word in self.uni_counts.keys():\n",
    "            prob = self._get_probability(given_trigram + (word,))\n",
    "            total_weight += prob\n",
    "            possible_next_words.append((word, prob))\n",
    "\n",
    "        # Add a small epsilon to the probabilities to ensure they are all greater than zero\n",
    "        epsilon = 1e-6\n",
    "        for i in range(len(possible_next_words)):\n",
    "            possible_next_words[i] = (\n",
    "                possible_next_words[i][0],\n",
    "                possible_next_words[i][1] + epsilon,\n",
    "            )\n",
    "\n",
    "        # Choose the next word based on probabilities\n",
    "        next_word = random.choices(\n",
    "            [word for word, _ in possible_next_words],\n",
    "            weights=[prob for _, prob in possible_next_words],\n",
    "        )[0]\n",
    "\n",
    "        return next_word\n",
    "\n",
    "    def calculate_perplexity(self, text):\n",
    "        log_prob_sum = 0\n",
    "        N = len(text)\n",
    "        for i in range(2, N):\n",
    "            context = tuple(text[i - 2 : i])\n",
    "            next_word = text[i]\n",
    "            prob = self._get_probability(context + (next_word,))\n",
    "            # Avoid taking log of zero by adding a small epsilon\n",
    "            log_prob_sum += math.log(prob + 1e-10)\n",
    "\n",
    "        # Compute perplexity using the formula\n",
    "        perplexity = math.exp(-log_prob_sum / (N - 2))\n",
    "        return perplexity\n",
    "\n",
    "\n",
    "with open(\"Moby_dick.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    text = tokenize(text)\n",
    "\n",
    "m = NGramModelWithBackoff(text)\n",
    "print(m.generate_text(20))\n",
    "# print(m.calculate_perplexity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on test set: 1902654688.830192\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Open and read the text file\n",
    "with open(\"Moby_dick.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize the text\n",
    "text_tokens = tokenize(text)\n",
    "\n",
    "# Shuffle the tokens to randomize the order\n",
    "random.shuffle(text_tokens)\n",
    "\n",
    "# Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(text_tokens) * split_ratio)\n",
    "\n",
    "# Split the tokens into training and test sets\n",
    "train_tokens = text_tokens[:split_index]\n",
    "test_tokens = text_tokens[split_index:]\n",
    "\n",
    "# Create an instance of the NGramModelWithProbabilities class\n",
    "m_with_prob = NGramModelWithBackoff(train_tokens)\n",
    "\n",
    "# Calculate perplexity using the test set\n",
    "perplexity = m_with_prob.calculate_perplexity(test_tokens)\n",
    "print(\"Perplexity on test set:\", perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
